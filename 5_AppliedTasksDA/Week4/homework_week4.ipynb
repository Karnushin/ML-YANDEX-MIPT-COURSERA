{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking\n",
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(vector, k=None):\n",
    "    \n",
    "    if k is not None:\n",
    "        if k > len(vector):\n",
    "            raise ValueError(\"k cannot be more than length of vector\")\n",
    "        vector = vector[:k]\n",
    "    \n",
    "    return 1 / len(vector) * sum(vector)\n",
    "\n",
    "def avg_precision_at_k(vector, k=None):\n",
    "    \n",
    "    if k is not None:\n",
    "        if k > len(vector):\n",
    "            raise ValueError(\"k cannot be more than length of vector\")\n",
    "        vector = vector[:k]\n",
    "\n",
    "    numer = 0\n",
    "    for i in range(len(vector)):\n",
    "        numer += vector[i] * precision_at_k(vector[:i+1])\n",
    "\n",
    "    return numer / sum(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(avg_precision_at_k([1,1,0,0]) - avg_precision_at_k([1,0,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = []\n",
    "buy = []\n",
    "with open('coursera_sessions_train.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        l = line.split(';')\n",
    "        v = (l[0].split(','))\n",
    "        b = (l[1].split(','))\n",
    "        if v[0] == '\\n':\n",
    "            continue\n",
    "        if b[0] != '\\n':\n",
    "            temp = b[-1].split('\\n')[0]\n",
    "            b[-1] = temp\n",
    "            buy.append(b)\n",
    "        \n",
    "        view.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = np.array(list(itertools.chain(*view))).astype(int)\n",
    "buy = np.array(list(itertools.chain(*buy))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356177"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_view, d_buy = {}, {}\n",
    "\n",
    "for i in view:\n",
    "    d_view.setdefault(i, 0)\n",
    "    d_view[i] += 1\n",
    "    \n",
    "for i in buy:\n",
    "    d_buy.setdefault(i, 0)\n",
    "    d_buy[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k, v in d_view.items():\n",
    "#    d_view[k] = d_view[k] / len(view)\n",
    "    \n",
    "#for k, v in d_buy.items():\n",
    "#    d_buy[k] = d_buy[k] / len(buy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "popularity_train = sorted(d_view.items(), key=lambda x: x[1], reverse=True)\n",
    "purchase_train = sorted(d_buy.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coursera_sessions_test.txt', 'r') as f:\n",
    "    test = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading train and test data\n",
    "with open('coursera_sessions_train.txt', 'r') as f:\n",
    "    sess_train = f.read().splitlines()\n",
    "with open('coursera_sessions_test.txt', 'r') as f:\n",
    "    sess_test = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create train array splitted by looks (look_items) and purchases (pur_items)\n",
    "sess_train_lp = []\n",
    "for sess in sess_train:\n",
    "    look_items, pur_items = sess.split(';')\n",
    "    look_items = list(map(int, look_items.split(',')))\n",
    "    if len(pur_items) > 0:\n",
    "        pur_items = list(map(int, pur_items.split(',')))\n",
    "    else:\n",
    "        pur_items = []\n",
    "    sess_train_lp.append([look_items, pur_items])\n",
    "\n",
    "#test\n",
    "sess_test_lp = []\n",
    "for sess in sess_test:\n",
    "    look_items, pur_items = sess.split(';')\n",
    "    look_items = map(int, look_items.split(','))\n",
    "    if len(pur_items) > 0:\n",
    "        pur_items = map(int, pur_items.split(','))\n",
    "    else:\n",
    "        pur_items = []\n",
    "    sess_test_lp.append([look_items, pur_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_train_l = [row[0] for row in sess_train_lp]\n",
    "sess_train_l_np = np.array( [id_n for sess in sess_train_l for id_n in sess] )\n",
    "\n",
    "# Array of unique ids and looks in train data\n",
    "sess_train_l_cnt = np.transpose(np.unique(sess_train_l_np, return_counts=True)) #==d_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# Array of purchases\n",
    "sess_train_p = [row[1] for row in sess_train_lp]\n",
    "sess_train_p_np = np.array( [id_n for sess in sess_train_p for id_n in sess] )\n",
    "\n",
    "# Array of unique ids and purchases in train dataset\n",
    "sess_train_p_cnt = np.transpose(np.unique(sess_train_p_np, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356177, 5374, 77064, 4479)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sess_train_l_np), len(sess_train_p_np), len(sess_train_l_cnt), len(sess_train_p_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sorting arrays of looks and purchases by counts\n",
    "sess_train_l_cnt = sess_train_l_cnt[sess_train_l_cnt[:,1].argsort()][::-1]\n",
    "sess_train_p_cnt = sess_train_p_cnt[sess_train_p_cnt[:,1].argsort()][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_rec_metrics(session, reccomendations, k):\n",
    "    purchase = 0\n",
    "    for ind in reccomendations:\n",
    "        if ind in session:\n",
    "            purchase += 1 \n",
    "    precision = purchase / k\n",
    "    recall = purchase / len(session)\n",
    "    return(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_1_tr_l, rec_at_1_tr_l = [], []\n",
    "prec_at_5_tr_l, rec_at_5_tr_l = [], []\n",
    "k1, k5 = 1, 5\n",
    "for i, sess_p in enumerate(sess_train_p):\n",
    "    # skip sessions without purchases\n",
    "    if sess_p == []: continue\n",
    "    \n",
    "    # looks ids\n",
    "    sess_l = sess_train_l[i]\n",
    "\n",
    "    # sorted looks ids indices in sess_train_l_cnt array\n",
    "    # sort in accordance with looks counts\n",
    "    l_ind_sess = []\n",
    "    for j in range(len(sess_l)):\n",
    "        l_ind_sess.append(np.where(sess_train_l_cnt[:,0] == sess_l[j])[0][0])\n",
    "    l_ind_sess_sorted = np.unique(l_ind_sess)\n",
    "    \n",
    "    # k1 recommendations\n",
    "    num_of_recs_k1 = min(k1, len(sess_l))\n",
    "    if num_of_recs_k1 == 0: continue\n",
    "    recs_k1 = sess_train_l_cnt[l_ind_sess_sorted[:num_of_recs_k1],0]\n",
    "    \n",
    "    # k1 metrics\n",
    "    prec_1, rec_1 = prec_rec_metrics(sess_p, recs_k1, k1)\n",
    "    prec_at_1_tr_l.append(prec_1)\n",
    "    rec_at_1_tr_l.append(rec_1)\n",
    "    \n",
    "    # k5 recommendations\n",
    "    num_of_recs_k5 = min(k5, len(sess_l))\n",
    "    if num_of_recs_k5 == 0: continue\n",
    "    recs_k5 = sess_train_l_cnt[l_ind_sess_sorted[:num_of_recs_k5],0]\n",
    "    \n",
    "    # k5 metrics\n",
    "    prec_5, rec_5 = prec_rec_metrics(sess_p, recs_k5, k5)\n",
    "    prec_at_5_tr_l.append(prec_5)\n",
    "    rec_at_5_tr_l.append(rec_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prec_at_1_tr_l = np.mean(prec_at_1_tr_l)\n",
    "avg_rec_at_1_tr_l = np.mean(rec_at_1_tr_l)\n",
    "avg_prec_at_5_tr_l = np.mean(prec_at_5_tr_l)\n",
    "avg_rec_at_5_tr_l = np.mean(rec_at_5_tr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: 0.44 0.51 0.83 0.21\n"
     ]
    }
   ],
   "source": [
    "r1 = '%.2f' % round(avg_rec_at_1_tr_l, 2)\n",
    "p1 = '%.2f' % round(avg_prec_at_1_tr_l, 2)\n",
    "r5 = '%.2f' % round(avg_rec_at_5_tr_l, 2)\n",
    "p5 = '%.2f' % round(avg_prec_at_5_tr_l, 2)\n",
    "ans1 = ' '.join([r1, p1, r5, p5])\n",
    "print('Answer 1:', ans1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
