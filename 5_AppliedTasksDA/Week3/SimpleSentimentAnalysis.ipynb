{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, classifier):\n",
    "    return Pipeline([(\"vectorizer\", vectorizer),(\"classifier\", classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1, 2\n",
    "df = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=['class', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "df.loc[df['class'] == 'ham', 'class'] = 0\n",
    "df.loc[df['class'] == 'spam', 'class'] = 1\n",
    "df['class'] = df['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "0    4825\n",
      "1     747\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(by=['class'])['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8713)\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "cnt_vectorizer = CountVectorizer()\n",
    "X = cnt_vectorizer.fit_transform(df['text'])\n",
    "y = df['class'].values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=2, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825907143631246\n",
      "0.9311269283144492\n"
     ]
    }
   ],
   "source": [
    "#5 should be like this:\n",
    "print(cross_val_score(text_classifier(CountVectorizer(), logreg), df['text'], y, cv=10, n_jobs=-1).mean())\n",
    "# but to pass the task it have to be like this:\n",
    "print(cross_val_score(logreg, X, y, scoring=\"f1\", cv=10, n_jobs=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "test = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\"\n",
    "        , \"FreeMsg: Txt: claim your reward of 3 hours talk time\"\n",
    "        , \"Have you visited the last lecture on physics?\"\n",
    "        , \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\"\n",
    "        , \"Only 99$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=2, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0 0 0\n"
     ]
    }
   ],
   "source": [
    "X_test = cnt_vectorizer.transform(test)\n",
    "print(' '.join(logreg.predict(X_test).astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg, (2, 2): 0.816782323945987\n",
      "MultinomialNB, (2, 2): 0.9330215115853413\n",
      "Logreg, (3, 3): 0.7250161555467377\n",
      "MultinomialNB, (3, 3): 0.871265305963816\n",
      "Logreg, (1, 3): 0.9216311884303947\n",
      "MultinomialNB, (1, 3): 0.9472991994136064\n"
     ]
    }
   ],
   "source": [
    "#7, 8\n",
    "l = [(2, 2), (3, 3), (1,3)]\n",
    "for ll in l:\n",
    "    cv_score1 = cross_val_score(text_classifier(CountVectorizer(ngram_range=ll), logreg),\n",
    "                          df['text'], y, scoring=\"f1\", cv=10, n_jobs=-1).mean()\n",
    "    cv_score2 = cross_val_score(text_classifier(CountVectorizer(ngram_range=ll), MultinomialNB()),\n",
    "                          df['text'], y, scoring=\"f1\", cv=10, n_jobs=-1).mean()\n",
    "    print(f\"Logreg, {ll}: {cv_score1}\")\n",
    "    print(f\"MultinomialNB, {ll}: {cv_score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg, (2, 2): 0.816782323945987\n",
      "MultinomialNB, (2, 2): 0.6455015177985443\n",
      "Logreg, (3, 3): 0.7250161555467377\n",
      "MultinomialNB, (3, 3): 0.37871948524573595\n",
      "Logreg, (1, 3): 0.9216311884303947\n",
      "MultinomialNB, (1, 3): 0.8884859656061002\n"
     ]
    }
   ],
   "source": [
    "#8 like in 5 (to pass it have to be like this)\n",
    "for ll in l:\n",
    "    X = CountVectorizer(ngram_range=ll).fit_transform(df['text'])\n",
    "    cv_score1 = cross_val_score(logreg, X, y, scoring=\"f1\", cv=10, n_jobs=-1).mean()\n",
    "    cv_score2 = cross_val_score(MultinomialNB(), X, y, scoring=\"f1\", cv=10, n_jobs=-1).mean()\n",
    "    print(f\"Logreg, {ll}: {cv_score1}\")\n",
    "    print(f\"MultinomialNB, {ll}: {cv_score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707463275918908\n",
      "0.9650025390008258\n"
     ]
    }
   ],
   "source": [
    "#9 like in 5\n",
    "print(cross_val_score(text_classifier(TfidfVectorizer(), logreg), df['text'], y, cv=10, n_jobs=-1).mean())\n",
    "\n",
    "X = TfidfVectorizer().fit_transform(df['text'])\n",
    "print(cross_val_score(logreg, X, y, cv=10, n_jobs=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
